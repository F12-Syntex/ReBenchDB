---
title: "SOMns Performance Comparison"
output: html_fragment
# http://localhost:33333/compare/SOMns/0d020c65f5ff950d5a9f3a6a87c08585f136afc8/b93035d99ba0f066240c3515745111be7d151e00
params:
  baseline: "b0bd089afdb2f3437c52486630ceb82e96a741d9"
  change: "b3d66873c97cac6d4e2f79e8b6a91e3397161b62"
  baseline_color: "#729fcf"
  change_color: "#e9b96e"
  fast_color: "#e4ffc7"
  slow_color: "#ffcccc"
  faster_runtime_ratio: 0.95
  slower_runtime_ratio: 1.05
  db_user: null  # rdb_sm1
  db_pass: null
  db_name: rdb_sm1
  lib_dir: "."
---

```{r setup, include=FALSE, echo=FALSE, warning=FALSE}
source(paste0(params$lib_dir, "/common.R"), chdir=TRUE)
enable_chunk_timing()
```

```{r load-db, include=FALSE, echo=FALSE, warning=FALSE, timeit=TRUE}
baseline_hash <- params$baseline
change_hash <- params$change
baseline_hash6 <- substr(baseline_hash, 1, 6)
change_hash6 <- substr(change_hash, 1, 6)

baseline_color <- params$baseline_color
change_color <- params$change_color

color <- setNames(c(baseline_color, change_color), c(baseline_hash6, change_hash6))

library(dplyr)


# load_and_install_if_necessary("psych")   # uses only geometric.mean
rebenchdb <- connect_to_rebenchdb(params$db_name, params$db_user, params$db_pass)
result <- get_measures_for_comparison(rebenchdb, baseline_hash, change_hash)
disconnect_rebenchdb(rebenchdb)
```


```{r comp, timeit=TRUE}
warmup <- result %>%
  filter(!grepl("startup", suite, fixed = TRUE),
         !grepl("interp", exe, fixed = TRUE))

peak <- result %>%
  group_by(commitid, exe, suite, bench) %>%
  filter(is.na(warmup) | iteration >= warmup)


base <- peak %>%
  filter(commitid == baseline_hash6) %>%
  group_by(exe, suite, bench) %>%
  summarise(base_mean = mean(value),
            base_median = median(value))

norm <- peak %>%
  left_join(base, by = c("exe", "suite", "bench")) %>%
  group_by(exe, suite, bench) %>%
  transform(ratio_mean = value / base_mean,
            ratio_median = value / base_median)

stats <- norm %>%
  group_by(commitid, exe, suite, bench) %>%
  filter(is.na(warmup) | iteration >= warmup) %>%
  summarise(
    unit = unit[1],
    min = min(value),
    max = max(value),
    sd = sd(value),
    mean = mean(value),
    median = median(value),
    samples = length(value),
            
    # mean_ratio_mean = mean(ratio_mean),
    # median_ratio_median = median(ratio_mean),
    # mean_ratio_median = mean(ratio_median),
    lowerBCI95 = 0, get_bca(value)$lower,
    upperBCI95 = 0, get_bca(value)$upper,
            
    ratio = median / base_median[1],
    ratioLower = lowerBCI95 / base_median[1],
    ratioUpper = upperBCI95 / base_median[1],
            
    change_m = ratio - 1,
    change_l = ratioLower - 1,
    change_u = ratioUpper - 1)

geometric.mean <- function(x) { exp(mean(log(x))) }

## Are we faster/slower? have a rough 5% boundary for all the noise
slower_category <- function(data) {
  m <- geometric.mean(data)
  if (m > 1.05) {
    return(TRUE)
  } else if (m < 0.95) {
    return(FALSE)
  } else {
    return(NA)
  }
}

stats_suite <- stats %>%
  filter(commitid == change_hash6) %>% # need to remove it so that statistics are accurate, or put it into the group
  group_by(exe, suite) %>%
  summarise(
    unit = unit[1],
    min = min(ratio),
    max = max(ratio),
    geomean = geometric.mean(ratio),
    num_benchmarks = length(ratio),
    slower = slower_category(ratio))

stats_all <- stats_suite %>%
  ungroup() %>%
  summarise(
    unit = unit[1],
    min = min(geomean),
    max = max(geomean),
    geomean = geometric.mean(geomean),
    num_benchmarks = sum(num_benchmarks))
```

## Summary Over All Benchmarks

```{r summary-suites, fig.height=2.5, fig.width=4.5, timeit=TRUE}
data_chg <- stats %>%
  filter(commitid == change_hash6) %>%
  select(commitid, exe, suite, bench, ratio) %>%
  droplevels()

data_chg_slow <- data_chg %>%
  left_join(stats_suite, by = c("exe", "suite")) %>%
  filter(commitid == change_hash6) %>%
  droplevels()

compare_runtime_ratio_of_suites_plot(
  data_chg_slow,
  params$slower_runtime_ratio, params$faster_runtime_ratio,
  params$fast_color, params$slow_color, color)
```

<dl class="row">
  <dt class="col-sm-3">Number of Benchmarks</dt>
  <dd class="col-sm-8">`r stats_all$num_benchmarks`</dd>

  <dt class="col-sm-3">Geometric Mean</dt>
  <dd class="col-sm-8">`r round(stats_all$geomean, 3)` (min. `r r2(stats_all$min)`, max. `r r2(stats_all$max)`)</dd>
</dl>


## Benchmark Performance

<dl class="row">
  <dt class="col-sm-2">Baseline</dt>
  <dd class="col-sm-9"><span class="baseline-badge">`r baseline_hash6`</span></dd>

  <dt class="col-sm-2">Change</dt>
  <dd class="col-sm-9"><span class="change-badge">`r change_hash6`</span></dd>
  
<dt class="col-sm-2">Significant Change</dt>
<dd class="col-sm-9"><div class="form-row">
<input type="range" class="col-6 custom-range" min="0" max="15" step="0.5" id="significance" style="padding-top: 1.75ex; padding-right: 1em;" value="5">
<input type="text" readonly class="col-4 form-control-plaintext" id="significance-val" value="5%">
</div></dd>
</dl>

```{r suites, results='asis', echo=FALSE, dev='svg', fig.keep='all', fig.height=0.3, fig.width=3, timeit=TRUE}

for (e in levels(norm$exe)) {
  data_e <- norm %>%
    filter(exe == e) %>%
    droplevels()

  for (s in levels(data_e$suite)) {
    data_s <- data_e %>%
      filter(suite == s) %>%
      droplevels()

    cp("<h3>", s, "</h3>")
    cp('<div class="title-executor">Executor: ', e, "</div>")

    cp('<table class="table table-sm benchmark-details">')
    cp('<thead><tr>
<th scope="col"></th>
<th scope="col"></th>
<th scope="col" title="Number of Samples">#M</th>
<th scope="col">mean in ', levels(data_s$unit), '</th>
<th scope="col">median in ', levels(data_s$unit), '</th>
<th scope="col">change in %</th>
</tr></thead>')
    
    
    for (b in levels(data_s$bench)) {
      data_b <- data_s %>%
        filter(bench == b) %>%
        droplevels()
      
      cp('<tr>')
      
      cp('<th scope="row">',  b, '</th>')
      
      cp('<td>')
      p <- small_inline_comparison(data_b)
      print(p)
      cp('</td>')
      
      stats_b <- stats %>%
        filter(bench == b, suite == s, exe == e, commitid == change_hash6) %>%
        droplevels()
      
      cp('<td class="stats-samples">', stats_b$samples, '</td>')
      cp('<td><span class="stats-mean" title="mean">', r2(stats_b$mean), '</span><span class="stats-sd" title="standard deviation">', r2(stats_b$sd), '</span></td>')
      cp('<td><span class="stats-median" title="median">', r2(stats_b$median), '</span><span class="stats-min" title="minimum">', r2(stats_b$min), '</span><span class="stats-max" title="maximum">', r2(stats_b$max),'</span></td>')
      cp('<td><span class="stats-change" title="change over median">', pro(stats_b$change_m), '</span><span class="stats-change-l" title="lower bound of 95% bootstrap confidence interval">', pro(stats_b$change_l), '</span><span class="stats-change-u" title="upper bound of 95% bootstrap confidence interval">', pro(stats_b$change_u), '</span></td>')

      cp('</tr>')
    }
    
    cp('</table>')
  }
}
```


## Warmup Behavior

This section excludes all interpreter-only and startup benchmarks.
```{r warmup-plots, echo=FALSE, results='asis', dev='svg', fig.keep='all', fig.width=6, fig.height=2.5, timeit=TRUE}
# b <- "Mandelbrot"

for (e in levels(warmup$exe)) {
  data_e <- warmup %>%
    filter(exe == e) %>%
    droplevels()
  
  for (s in levels(data_e$suite)) {
    data_s <- data_e %>%
      filter(suite == s) %>%
      droplevels()
    
    for (b in levels(data_s$bench)) {
      data_b <- data_s %>%
        filter(bench == b) %>%
        droplevels()
      
      cp('<div><span class="warmup-benchmark">', b, '</span><span class="warmup-suite">', s, '</span><span class="warmup-exe">', e, '</span>')
      cp('<div class="warmup-plot">')
      warmup_plot(data_b, b, s, e)
      cp('</div></div>')
    }
  }
}
```
