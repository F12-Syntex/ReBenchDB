# -*- mode: yaml -*-
# Config file for ReBench
default_experiment: benchmarks
default_data_file: 'rebench.data'

reporting:
    # Benchmark results will be reported to ReBenchDB
    rebenchdb:
        # this url needs to point to the API endpoint
        db_url: https://rebench.stefan-marr.de/rebenchdb
        repo_url: https://github.com/smarr/ReBenchDB
        record_all: true # make sure everything is recorded
        project_name: ReBenchDB

runs:
    max_invocation_time: 6000
    min_iteration_time: 1

benchmark_suites:
    normal:
        gauge_adapter: RebenchLog
        command: "harness.js %(benchmark)s %(iterations)s 1 %(input)s "
        location: dist/src/benchmarks
        iterations: 10
        invocations: 1
        input_sizes:
            - small
            - medium
            - large
        benchmarks:
            - store-results
            - fetch-results
            - compute-timeline
            - render-report
    full:
        gauge_adapter: RebenchLog
        command: "harness.js %(benchmark)s %(iterations)s 1 %(input)s "
        location: dist/src/benchmarks
        iterations: 1
        invocations: 1
        input_sizes:
            - full
        benchmarks:
            - store-results
            - compute-timeline
            - render-report

executors:
    benchmarks:
        executable: /usr/local/bin/node
        env:
            RDB_USER: docker
            RDB_PASS: docker
            RDB_HOST: localhost
            RDB_DB:   rebenchdb

# define the benchmarks to be executed for a re-executable benchmark run
experiments:
    benchmarks:
        description: All benchmarks
        suites:
            - normal
            - full
        executions:
            - benchmarks
